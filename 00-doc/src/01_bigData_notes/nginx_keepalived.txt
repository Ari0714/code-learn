
--------------------------------------------------------------install-------------------------------------------------------------

-------------------configure vip-------------------

搭建机器
CDH4	10.91.2.104
CDH5	10.91.2.105

cp ifcfg-bond0 ifcfg-bond0-vip
虚拟网络：10.91.2.11

启动
ifup ifcfg-bond0-vip
ifdown ifcfg-bond0-vip


-------------------deploy nginx-------------------

yum -y install pcre-devel zlib-devel popt-devel openssl-devel openssl gcc-c++


wget http://www.nginx.org/download/nginx-1.21.0.tar.gz

tar -zxvf nginx-1.21.0.tar.gz

./configure --with-stream
make && make install



./configure --prefix=/home/deployer/soft/nginx_backward_proxy --with-stream --with-http_ssl_module



--- start
cd /usr/local/nginx

启动
sbin/nginx

停止
sbin/nginx -s stop

重启
sbin/nginx -s reopen

-------------------deploy keepalived-------------------

yum install -y gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel


# tar -zxvf keepalived-1.2.18.tar.gz
# cd keepalived-1.2.18
# ./configure --prefix=/usr/local/keepalived
# make && make install


--- 将 keepalived 安装成 Linux 系统服务
mkdir /etc/keepalived
cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/


cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/
cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/
ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin/
ln -s /usr/local/keepalived/sbin/keepalived /sbin/


设置 keepalived 服务开机启动
# chkconfig keepalived on



--- keepalived master脚本

vim /etc/keepalived/keepalived.conf

! Configuration File for keepalived
global_defs {
	## keepalived 自带的邮件提醒需要开启 sendmail 服务。 建议用独立的监控或第三方 SMTP
	router_id liuyazhuang133 ## 标识本节点的字条串，通常为 hostname
}
## keepalived 会定时执行脚本并对脚本执行的结果进行分析，动态调整 vrrp_instance 的优先级。如果脚本执行结果为 0，并且 weight 配置的值大于 0，则优先级相应的增加。如果脚本执行结果非 0，并且 weight配置的值小于 0，则优先级相应的减少。其他情况，维持原本配置的优先级，即配置文件中 priority 对应的值。
vrrp_script chk_nginx {
	script "/etc/keepalived/nginx_check.sh" ## 检测 nginx 状态的脚本路径
	interval 2 ## 检测时间间隔
	weight -20 ## 如果条件成立，权重-20
}
## 定义虚拟路由， VI_1 为虚拟路由的标示符，自己定义名称
vrrp_instance VI_1 {
	state MASTER ## 主节点为 MASTER， 对应的备份节点为 BACKUP
	interface bond0-vip ## 绑定虚拟 IP 的网络接口，与本机 IP 地址所在的网络接口相同， 我的是 bond0-vip
	virtual_router_id 33 ## 虚拟路由的 ID 号， 两个节点设置必须一样， 可选 IP 最后一段使用, 相同的 VRID 为一个组，他将决定多播的 MAC 地址
	mcast_src_ip 10.91.2.104 ## 本机 IP 地址
	priority 100 ## 节点优先级， 值范围 0-254， MASTER 要比 BACKUP 高
	nopreempt ## 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题
	advert_int 1 ## 组播信息发送间隔，两个节点设置必须一样， 默认 1s
	## 设置验证信息，两个节点必须一致
	authentication {
		auth_type PASS
		auth_pass 1111 ## 真实生产，按需求对应该过来
	}
	## 将 track_script 块加入 instance 配置块
	track_script {
		chk_nginx ## 执行 Nginx 监控的服务
	} #
	# 虚拟 IP 池, 两个节点设置必须一样
	virtual_ipaddress {
		10.91.2.11 ## 虚拟 ip，可以定义多个
	}
}




--- keepalived backup script

vim /etc/keepalived/keepalived.conf


! Configuration File for keepalived
global_defs {
	router_id cdh04
}
vrrp_script chk_nginx {
	script "/etc/keepalived/nginx_check.sh"
	interval 2
	weight -20
}

vrrp_instance VI_1 {
	state MASTER
	interface bond0-vip
	virtual_router_id 33
	mcast_src_ip 10.91.2.104
	priority 100
	nopreempt
	advert_int 1
	authentication {
		auth_type PASS
		auth_pass 1111
	}
	track_script {
		chk_nginx
	}
	virtual_ipaddress {
		10.91.2.11
	}
}



! Configuration File for keepalived
global_defs {
	router_id cdh05
}
vrrp_script chk_nginx {
	script "/etc/keepalived/nginx_check.sh"
	interval 2
	weight -20
}
vrrp_instance VI_1 {
	state BACKUP
	interface bond0-vip
	virtual_router_id 33
	mcast_src_ip 10.91.2.105
	priority 90
	advert_int 1
	authentication {
		auth_type PASS
		auth_pass 1111
	}
	track_script {
		chk_nginx
	}
	virtual_ipaddress {
		10.91.2.11
	}
}




--- nginx检测脚本
vim /etc/keepalived/nginx_check.sh

#!/bin/bash
A=`ps -C nginx –no-header |wc -l`
if [ $A -eq 0 ];then
/usr/local/nginx/sbin/nginx
sleep 2
if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then
	killall keepalived
fi
fi



chmod +x /etc/keepalived/nginx_check.sh



--- 启动keepalived
service keepalived start

service keepalived stop

systemctl status keepalived.service





--- 测试 keepalived

service keepalived stop
/usr/local/nginx/sbin/nginx -s stop


--- 配置nginx

server {
  listen 9030;
  server_name localhost;

  location / {
    proxy_pass http://10.74.64.164:9030;
  }

}





--- 配置生产环境

	# Oozie代理
    upstream oozie_servers
    {
        server 10.91.2.101:11000 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.102:11000 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.103:11000 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.104:11000 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.105:11000 weight=1 max_fails=2 fail_timeout=60s; #server
    }
	server {
		listen 11001;   #nginx监听的端口
		server_name localhost; #cdh中web页面的端口+内网ip
		location / {
			proxy_pass http://oozie_servers;#这里的名称与你上面配置的名称一致
		}
	}

	# hiveserver2代理
    upstream hiveserver2_servers
    {
        server 10.91.2.103:10000 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.104:10000 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.105:10000 weight=1 max_fails=2 fail_timeout=60s; #server
    }
	server {
		listen 10001;   #nginx监听的端口
		server_name localhost2; #cdh中web页面的端口+内网ip
		location / {
			proxy_pass http://hiveserver2_servers;#这里的名称与你上面配置的名称一致
		}
	}

	# hive metastore代理
    upstream metastore_servers
    {
        server 10.91.2.103:9083 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.104:9083 weight=1 max_fails=2 fail_timeout=60s; #server
        server 10.91.2.105:9083 weight=1 max_fails=2 fail_timeout=60s; #server
    }
	server {
		listen 9084;   #nginx监听的端口
		server_name localhost3; #cdh中web页面的端口+内网ip
		location / {
			proxy_pass http://metastore_servers;#这里的名称与你上面配置的名称一致
		}
	}



# StarRocks代理
stream
{
    log_format proxy '$remote_addr [$time_local] '
    '$protocol $status $bytes_sent $bytes_received '
    '$session_time "$upstream_addr" '
    '"$upstream_bytes_sent" "$upstream_bytes_received" "$upstream_connect_time"';


    access_log /var/log/nginx/stream.log proxy;


    upstream starrocks-tcp1
    {
        server 10.91.2.191:9030 weight=1 max_fails=2 fail_timeout=60s; #Follower
        server 10.91.2.192:9030 weight=1 max_fails=2 fail_timeout=60s; #leader
        server 10.91.2.193:9030 weight=1 max_fails=2 fail_timeout=60s; #Follower
    }
    server
    {
        listen 9031;
        proxy_pass starrocks-tcp1;
        proxy_timeout 60s;
        proxy_connect_timeout 60s;
    }
}


Hadoop 1.x vs 2.x
1.
common => hdfs => MR(计算+资源调度)
common => hdfs => yarn（资源调度） + mr（计算）
2.HA

nameNode：元数据（描述数据的数据）
datanode：数据
secondary namedone：监视dn，间隔时间获取数据快照

yarn架构：
resourcemanager =》监控nodemanager + 启动且监控applicationmasteram =》调度nm
流程：job =》rm =》nm =》am数据切分，申请资源 =》nm启动container完成资源调度

mapreduce:
map: 并行处理输入数据
reduce：对map结果汇总



--------------------------------------------------------------hdfs-------------------------------------------------------------
定义：分布式文件存储系统
特点：适合一次写入，多次写出的场景，不能修改
优点 =》可靠：多副本机制
缺点 =》不适合低延时数据访问；无法高效存储大量小文件（占用大量nm的目录和块信息，寻址时间>读取时间）；不支持并发写入，文件修改
增加client：上传文件时切分成block后上传，命令管理hdfs（hdfs namename -format）
hdfs文件块大小：128M，寻址时间为传输时间的1%最好，100MB/s，寻址时间1ms。 太小：寻址时间长（文件碎片） 太大：mr慢，程序满

Hadoop fs 命令分类

本地-》HDFS
    put
    copyFromLocal
    moveFromLocal
    appendToFile

HDFS -》 HDFS
   -cp
	rm
    mv
    chown
    chgrp
    chmod
    mkdir
    du
    df
    cat
	ls
	tail

HFDS-》本地
    get
    getmerge
    copyToLocal

hdfs操作：
创建hdfs目录：hdfs dfs -mkdir -p /usr/atguigu/input
存入文件： hdfs dfs -put README.txt /user/atguigu/input
试运行：hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input/README.txt /user/atguigu/input12
下载：hadoop fs -get /user/atguigu/input/README.txt ./


启停HDFS：
start-dfs.sh /stop-dfs.sh
YARN
start-yarn.sh/stop-yarn.sh
jobhistory
mr-jobhistory-daemon.sh start historyserver
 ==》192.168.30.137:19888/jobhistory

namenode初始化
hdfs namenode -format

安全模式
hadoop dfsadmin -safemode leave


hdfs客户端操作（环境，API） =》 见文档


hdfs写：
文件（200M）=》client 请求上传 =》nm检查相同文件，权限等 =》可以上传 =》client切分文件 =》 client建立输出流 =》请求上传0-128MB第一部分 =》nm返回dn节点 =》client与dn建立连接并上传数据
hdfs读：
client 请求下载 =》nm响应文件是否存在 =》client请求下载第一个block =》nm返回dn节点 =》client建立输入流链接dn01获取数据

2nn作用：合并edit.log和fsimage
checkpoint触发条件：nm启动，时间到了（1h），edit数据满了（每分钟检查，100W操作次数）
存储路径：name节点上：/opt/loghdp/dfs/name/current  edit.log不删，fsimage留两个

nd和dn：
dn启动 =》dn注册 =》每一小时上报数据信息，每3s发送心跳


多目录：每个目录存储数据不一样，数据拓展


--------------------------------------------------------------mapreduce-------------------------------------------------------------
定义：分布式运算程序的编程的编程框架
优点：易于变成，拓展
缺点：慢
mapreduce核心思想：map =》映射（k,v）=》 shuffle  =》 reduce：汇总

hadoop序列化

切片和mapTask并行度
maptask由切片数量决定
切片大小：128MB==block大小，不平均，减少网络传输
考虑整片：300，10，10  =》 5 ，不是3

mapreduce整体流程：worldcount文件 =》 客户端（切片） =》 提交到yarn的rm =》rm计算maptask =》maptask把文件处理成kv =》
					进入环形缓冲区 =》一边写数据，一边写索引 100M*80% 溢出 =》分区，排序 =》溢出到文件，分区且区内有序 =》merge归并排序 =》
					=》一个reducetask拿一个分区计算和


hadoop数据压缩：
目的：压缩数据，减少IO量，但增加了CPU负担
场景：IO密集型用压缩，运算密集型不用
lzo：压缩率合理（2倍），压缩解压速度（50，70），支持split
snappy：不支持split，压缩解压速度（250，500）


--------------------------------------------------------------yarn-------------------------------------------------------------
作业提交过程：ob =》rm =》nm =》am数据切分，申请资源 =》nm启动container完成资源调度
资源调度器：FIFO（先进先出），Capacity Scheduler（按照到达时间排序，先进先服务），Fair Scheduler（按照缺额排序，缺额大者优先）


优化方法
瓶颈：1.计算机性能（cpu，内存，磁盘，网络）
	  2.IO
	  1.数据倾斜
	  2.map和reduce数设置不合理
	  3.map太久，reduce等待长
	  4.小文件多
	  5.大量不可分块大文件
	  6.split次数多
	  7.merge次数多

调优：
1.数据输入阶段：合并小文件
2.map阶段：减少溢写（split）次数，合并次数（merge）
3.reduce阶段：合理map和reduce阶段，设置map和reduce共存，
4.IO传输:数据压缩,用Snappy和lzo
5.数据倾斜：

小文件处理
1.源头合并


HA高可用：
原理：配置active/standby两个dn热备切换



-----操作
查看日志：yarn logs -applicationId application_1723175437205_8249 > a.txt

批量kill掉任务
yarn application -list | grep application_ | grep RUNNING | grep Check | awk -F" " '{print $1}' | xargs yarn application -kill


yarn application -list | grep application_ | grep ACCEPTED | grep Check | awk -F" " '{print $1}' | xargs yarn application -kill

yarn application -list | grep application_ | grep ACCEPTED | awk -F" " '{print $1}' | xargs yarn application -kill


yarn application -list | grep RUNNING | grep A=Check_ | wc -l

yarn application -list | grep RUNNING | grep A=Output_ | wc -l

yarn application -list | grep RUNNING | grep A=Accessdata_ | wc -l

yarn application -list | grep RUNNING | grep 'Hive on Spark'  | wc -l

yarn application -list | grep RUNNING | grep 'Sqlcompute'  | wc -l


-- analyze table
ANALYZE TABLE ods.ods_obg_sap_hana_erpacc_pd1clnt888_likp COMPUTE STATISTICS;


